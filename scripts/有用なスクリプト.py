import math, os
from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers
from loguru import logger

from transformers import AutoTokenizer, BitsAndBytesConfig, Gemma3ForCausalLM

from rich.console import Console
from rich.panel import Panel
from rich.text import Text
from rich import box

# FIX: Import a valid theme object
from rich.terminal_theme import SVG_EXPORT_THEME

def train_tokenizer(
    file_path: str | list[str],
    vocab_size=5000,
    text_to_compress="å¾è¼©ã‚ãŒã¯ã„ã¯çŒ«ã§ã‚ã‚‹ã€‚åå‰ã¯ã¾ã ç„¡ã„ã€‚",
    silent_train=False,
) -> Tokenizer:

    if isinstance(file_path, str):
        assert os.path.exists(
            file_path
        ), f"è¨“ç·´ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« {file_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
    elif isinstance(file_path, list):
        for file in file_path:
            assert os.path.exists(
                file
            ), f"è¨“ç·´ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« {file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
    else:
        raise

    VOCAB_SIZE = vocab_size  # è¾žæ›¸ã®å¤§ãã•

    # åˆæœŸåŒ–
    tokenizer = Tokenizer(models.BPE())  # huggingface ã®å…¬å¼BPEå®Ÿè£…ã‚’ä½¿ã„ã¾ã™
    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)
    tokenizer.decoder = decoders.ByteLevel()

    trainer = trainers.BpeTrainer(vocab_size=VOCAB_SIZE)

    # Train the tokenizer
    print(f"Tokenizerã®æŒ‡å®šå˜èªžæ•°ã¯ {VOCAB_SIZE}...")
    if isinstance(file_path, str):
        tokenizer.train(files=[file_path], trainer=trainer)
    else:
        tokenizer.train(files=file_path, trainer=trainer)
    print("è¨“ç·´å®Œäº†")
    if silent_train:
        return tokenizer

    # --- 3. æ¯”è¼ƒç”¨ã‚µãƒ³ãƒ—ãƒ«ã§è©¦ã™ ---
    print()
    print(f"--- ãƒ†ã‚­ã‚¹ãƒˆå®¹é‡æ¯”è¼ƒ ---")
    print(f"æ¯”è¼ƒç”¨ã‚µãƒ³ãƒ—ãƒ«: '{text_to_compress}'")

    # --- 4.  'Unicode' (UTF-8)  ---
    # ã¨ã‚Šã‚ãˆãšUTFï¼˜ã®å®¹é‡ã‚’è¨ˆç®—ã™ã‚‹
    utf8_bytes = text_to_compress.encode("utf-8")
    utf8_bit_count = len(utf8_bytes) * 8  # ï¼‘Bytes ã¯ ï¼˜bits

    print()
    print(f"[UTF-8 å®¹é‡]")
    print(f"  bytes: {len(utf8_bytes)}")
    print(f"  bits (bytes * 8): {utf8_bit_count}")

    # --- 5. Calculate BPE Bits ---
    # Encode the text using our trained BPE model
    encoding = tokenizer.encode(text_to_compress)
    bpe_tokens = encoding.ids

    # The number of bits per token is determined by the vocabulary size.
    # We need log2(vocab_size) bits to represent any token ID.
    actual_vocab_size = tokenizer.get_vocab_size()
    bits_per_token = math.ceil(math.log2(actual_vocab_size))

    # Total bits = number of tokens * bits per token
    total_bpe_bits = len(bpe_tokens) * bits_per_token

    print()
    print(f"[BPE å®¹é‡]")
    print(f"  è¾žæ›¸å®¹é‡: {actual_vocab_size}")
    print(f"  ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ã®bitså¯†åº¦ (ceil(log2(vocab_size))): {bits_per_token}")
    print(f"  ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {len(bpe_tokens)}")
    print(f"  ãƒˆãƒ¼ã‚¯ãƒ³: {bpe_tokens}")
    print(f"  bits (ãƒˆãƒ¼ã‚¯ãƒ³æ•° * bits_per_token): {total_bpe_bits}")

    print()
    print("--- ðŸ“Š æœ€çµ‚çµæžœ ---")
    print(f"UTF-8 Bits: {utf8_bit_count}")
    print(f"BPE Bits:   {total_bpe_bits}")

    compression_ratio = utf8_bit_count / total_bpe_bits
    print(f"-> åœ§ç¸®æ¯”çŽ‡: {compression_ratio:.2f} (UTF-8 bits / BPE bits)")

    return tokenizer


def load_txt(path="./scripts/text/å¾è¼©ã¯çŒ«ã§ã‚ã‚‹utf8.txt") -> list[str]:
    with open(path, encoding="utf8") as f:
        lines = f.readlines()

    return lines


def load_gemini(model_name: str = "google/gemma-3-1b-it"):
    # quantization_config = BitsAndBytesConfig(load_in_8bit=True)
    
    model = Gemma3ForCausalLM.from_pretrained(
        model_name
    ).eval()
    
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    
    return model, tokenizer

def display_colored_box(words, colors, title="Output", filename = ""):
    """
    Displays words with individual colors in a wrapped, rounded box.
    """
    # 1. Create a Text object to hold the styled content
    styled_content = Text()

    # 2. Iterate through both lists simultaneously
    for word, color in zip(words, colors):
        styled_content.append(word, style=color)

    # 3. Create a Panel with rounded corners and padding
    panel = Panel(
        styled_content,
        title=title,
        box=box.ROUNDED,    # Rounded corners
        padding=(1, 2),     # (top/bottom, left/right) margins inside box
        expand=False        # False = fit to text; True = fit to terminal width
    )

    # 4. Print to console
    console = Console()
    # console.print(panel)
    
    if filename:
        console.save_svg(filename, title=title, theme=SVG_EXPORT_THEME)
        print(f"Successfully saved to {filename}")
